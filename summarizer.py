from transformers import MBartForConditionalGeneration, MBart50TokenizerFast

# Load tokenizer and model
model_name = "facebook/mbart-large-50-many-to-many-mmt"
tokenizer = MBart50TokenizerFast.from_pretrained(model_name)
model = MBartForConditionalGeneration.from_pretrained(model_name)

# Set target language to Urdu
tokenizer.src_lang = "ur_Arab"

# Example input
urdu_text = "ÛŒÛ Ø§ÛŒÚ© Ø¨ÛØª Ù„Ù…Ø¨ÛŒ ØªØ­Ø±ÛŒØ± ÛÛ’ Ø¬Ùˆ Ø§Ø±Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ù…ÛŒÚº Ù„Ú©Ú¾ÛŒ Ú¯Ø¦ÛŒ ÛÛ’ Ø§ÙˆØ± Ø§Ø³ Ú©Ø§ Ø®Ù„Ø§ØµÛ Ù†Ú©Ø§Ù„Ù†Ø§ ÛÛ’ ØªØ§Ú©Û ØµØ§Ø±Ù Ø¢Ø³Ø§Ù†ÛŒ Ø³Û’ Ø³Ù…Ø¬Ú¾ Ø³Ú©Û’Û”"

# Tokenize and summarize
inputs = tokenizer(urdu_text, return_tensors="pt", max_length=512, truncation=True)
generated_ids = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id["ur_Arab"], max_length=128)

# Decode and print summary
summary = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print("ğŸ” Summarized Text:\n", summary)
